<html>
  <head>
    <meta charset="UTF-8">
    <title>Audio samples from "DidiSpeech: A Large Scale Mandarin Speech Corpus"</title>
    <link rel="stylesheet" type="text/css" href="../../stylesheet.css"/>
    <link rel="shortcut icon" href="../../images/taco.png">
  </head>
  <body>
    <article>
      <header>
        <h1>Audio samples from "DidiSpeech: A Large Scale Mandarin Speech Corpus"</h1>
      </header>
    </article>

    <div><b>Authors:</b> Tingwei Guo, Cheng Wen, DongWei Jiang, Ne Luo, RuiXiong Zhang, ShuaiJiang Zhao, WuBo Li, Cheng Gong, Wei Zou, Kun Han, XianGang Li</div>
    <div><b>Abstract:</b> This paper introduces a new open-sourced Mandarin speech corpus, called DidiSpeech. It consists of about 800 hours of speech data at 48kHz sampling rate from 6000 speakers and the corresponding texts. All speech data in the corpus was recorded in quiet environment and is suitable for various speech processing tasks, such as voice conversion, multi-speaker text-to-speech and aucomatic speech recognation. We conduct experiments with multiple speech tasks and evaluate the performance, showing that it is promising to use the corpus for both academic research and practical application. The corpus is available at www.didichuxing.com.
    </div>

    <div>
      <h3>Voice conversion</h3>
      <h5>"Generative adversarial network or variational auto-encoder."</h5>
      <table>
        <tr><td>"原声"</td><td>合成样音</td></tr>
        <tr><td><audio controls><source src="demos/gan_or_vae.wav"></audio></td>
            <td><audio controls><source src="demos/gan_or_vae.wav"></audio></td></tr>
      </table>
    </div>
    <div>
      <h3>Multi-speaker speech synthesis</h3>
    </div>

  </body>
</html>
